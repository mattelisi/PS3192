---
title: "PS3192: Real World Data Science"
author: "Matteo Lisi"
format:
  revealjs:
    incremental: true
    auto-stretch: true
    theme: [default, matteo_rhul.css]
editor: visual
---

# Introduction to Machine Learning Concepts

## 

Some core components of 'data science'

- Data wrangling (data cleaning & preparation)
- Data visualization
- Statistics & probability
- Machine learning & predictive modeling
- Causal inference
- Big data & data engineering
- Applied context (actionable insights)
- Communication


## Learning Outcomes for today

-   Grasp **fundamental machine learning** concepts
-   Recognize typical pitfalls
-   Build and evaluate models in R

## Types of machine learning

- **Supervised learning** predict the next value based on a set of examples (regression, classification).
- **Unsupervised learning** data drive (clustering; dimensionality reduction, e.g. PCA).
- **Reinforcement learning** learn from mistakes.

## Supervised vs. Unsupervised Learning

**Supervised Learning**\
- We have input features $X$ and target labels/outcomes $y$\
- The algorithm learns a function $f(X)$ that predicts $y$ accurately\
- Examples: **Regression** (continuous outcomes), **Classification** (categorical outcomes)

**Unsupervised Learning**\
- We only have input features $X$, with no labeled outcome\
- The algorithm finds structure in the data (e.g., clusters, latent factors)\
- Examples: **Clustering** (e.g., gaussian mixture models), **Dimensionality Reduction** (PCA)

## Overfitting & Out-of-Sample Prediction

-   **Overfitting**: The model fits the training data too closely and fails to generalize\
-   **Bias-Variance Tradeoff**:
    -   High-variance models are flexible but prone to overfitting
    -   High-bias models are simpler but may underfit
-   **Out-of-Sample Prediction**:
    -   True test of a model is its performance on unseen (new) data

## Cross-Validation

1.  **Why Cross-Validation?**
    -   Need a reliable estimate of how a model performs on unseen data\
    -   Simply using one train/test split can be misleading
2.  **k-Fold Cross-Validation**
    -   Split data into \\(k\\) folds (subsets)\
    -   Train on \\(k - 1\\) folds, test on the remaining fold\
    -   Repeat for each fold; average performance across folds for a robust metric

## Case Study: Linear Regression

**Goal:** Predict a continuous outcome \\(y\\) from predictors \\(X\\).

\\\[ y = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p + \\epsilon \\\]

1.  **Train/Test Split or Cross-Validation**\
2.  **Fit the Model** on training data\
3.  **Evaluate** using metrics like RMSE, \\(R\^2\\), MAE

**Example in R**:

```{r, eval=FALSE}
# Suppose 'mydata' has columns: y, X1, X2
mydata <- read.csv("mydata.csv")

set.seed(123)  # for reproducibility
train_index <- sample(seq_len(nrow(mydata)), size = 0.7*nrow(mydata))
train_data <- mydata[train_index, ]
test_data  <- mydata[-train_index, ]

# Fit a linear model
model <- lm(y ~ X1 + X2, data = train_data)

# Predict on test data
preds <- predict(model, newdata = test_data)

# Calculate Mean Squared Error
mse <- mean((test_data$y - preds)^2)
mse
```

## Critical Thinking About Machine Learning

**Algorithmic Bias**

-   Biased training data can lead to unfair or discriminatory predictions
-   Must consider representation and fairness at each stage

**Transparency & Explainability**

-   Black-box models (e.g., deep nets) can be hard to interpret
-   Growing field of explainable AI (e.g., SHAP, LIME) to interpret predictions

**Ethical & Social Considerations**

-   Always consider impact on stakeholders and society
-   Responsible data collection and model deployment

## Summary & Next Steps

-   Machine Learning aims to learn patterns from data for prediction or discovery
-   Supervised vs. Unsupervised: labeled vs. unlabeled data tasks
-   Overfitting is a core challenge; cross-validation helps mitigate it
-   Linear Regression serves as a foundational supervised method
-   Ethical considerations are crucial for real-world applications

**Next Lecture**

-   Deeper dive into Classification and other Supervised Learning methods
-   Hands-on practice building models in R
