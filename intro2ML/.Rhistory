mean((pred_y - test_data$medv)^2)
mean((test_data$medv - mean(test_data$medv))^2)
# Create a random index for splitting
n <- nrow(bh_data)
train_index <- sample(seq_len(n), size = 100, replace = FALSE)
# Split data into 50% training and 50% test
train_data <- bh_data[train_index, ]
test_data  <- bh_data[-train_index, ]
# Save as CSV
write.csv(train_data, "california_housing_train.csv", row.names = FALSE)
write.csv(test_data, "california_housing_test.csv", row.names = FALSE)
# Print confirmation
print("Train and test datasets saved as CSV.")
str(train_data)
m0 <- lm(medv ~ ., data=train_data)
pred_y_train <- predict(m0)
mean((pred_y_train - train_data$medv)^2)
pred_y <- predict(m0, newdata=test_data)
mean((pred_y - test_data$medv)^2)
mean((test_data$medv - mean(test_data$medv))^2)
# Create a random index for splitting
n <- nrow(bh_data)
train_index <- sample(seq_len(n), size = 100, replace = FALSE)
# Split data into 50% training and 50% test
train_data <- bh_data[train_index, ]
test_data  <- bh_data[-train_index, ]
# Save as CSV
write.csv(train_data, "california_housing_train.csv", row.names = FALSE)
write.csv(test_data, "california_housing_test.csv", row.names = FALSE)
# Print confirmation
print("Train and test datasets saved as CSV.")
str(train_data)
m0 <- lm(medv ~ ., data=train_data)
pred_y_train <- predict(m0)
mean((pred_y_train - train_data$medv)^2)
pred_y <- predict(m0, newdata=test_data)
mean((pred_y - test_data$medv)^2)
mean((test_data$medv - mean(test_data$medv))^2)
# Create a random index for splitting
n <- nrow(bh_data)
train_index <- sample(seq_len(n), size = 100, replace = FALSE)
# Split data into 50% training and 50% test
train_data <- bh_data[train_index, ]
test_data  <- bh_data[-train_index, ]
# Save as CSV
write.csv(train_data, "california_housing_train.csv", row.names = FALSE)
write.csv(test_data, "california_housing_test.csv", row.names = FALSE)
# Print confirmation
print("Train and test datasets saved as CSV.")
str(train_data)
m0 <- lm(medv ~ ., data=train_data)
pred_y_train <- predict(m0)
mean((pred_y_train - train_data$medv)^2)
pred_y <- predict(m0, newdata=test_data)
mean((pred_y - test_data$medv)^2)
mean((test_data$medv - mean(test_data$medv))^2)
# Create a random index for splitting
n <- nrow(bh_data)
train_index <- sample(seq_len(n), size = 100, replace = FALSE)
# Split data into 50% training and 50% test
train_data <- bh_data[train_index, ]
test_data  <- bh_data[-train_index, ]
# Save as CSV
write.csv(train_data, "california_housing_train.csv", row.names = FALSE)
write.csv(test_data, "california_housing_test.csv", row.names = FALSE)
# Print confirmation
print("Train and test datasets saved as CSV.")
str(train_data)
m0 <- lm(medv ~ ., data=train_data)
pred_y_train <- predict(m0)
mean((pred_y_train - train_data$medv)^2)
pred_y <- predict(m0, newdata=test_data)
mean((pred_y - test_data$medv)^2)
mean((test_data$medv - mean(test_data$medv))^2)
summary(m0)
str(train_data)
train_data <- subset(train_data, select = -c(b))
test_data <- subset(test_data, select = -c(b))
write.csv(train_data, "california_housing_train.csv", row.names = FALSE)
write.csv(test_data, "california_housing_test.csv", row.names = FALSE)
#
str(train_data)
d_train <- read.csv("california_housing_train.csv")
as.formula("medv ~ rm")
formula <- as.formula("medv ~ rm")
dep_var <- all.vars(formula)[1]
dep_var
d_train[[outcome_var]]
outcome_var <- all.vars(formula)[1]
d_train[[outcome_var]]
d_train[outcome_var]
d_train[outcome_var]
str(mydata[outcome_var])
str(d_train[outcome_var])
str(d_train[[outcome_var]])
d_train[,-"medv"]
d_train[,-medv]
d_train[,-which(colnames(d_train)=="medv")]
var_list <- colnames(d_train[,-which(colnames(d_train)=="medv")])
dependent_var <- "medv"
var_list
dependent_var <- "medv"
# empty list to hold all formulae
all_formulas <- list()
# generate combinations of variables
for(i in 1:length(var_list)){
combinations <- combn(var_list, i)
num_combinations <- ncol(combinations)
# loop over combinations and create formulas
for(j in 1:num_combinations){
formula <- paste(dependent_var, "~", paste(combinations[,j], collapse = " + "))
all_formulas <- c(all_formulas, formula)
}
}
all_formulas
i=1
m <- list() #
m[[i] <- lm(formula, data = d_train)
m[[i]] <- lm(formula, data = d_train)
m[[i]]
summary(m <- list() # an empty list)
summary(m[[i]])
model_comparison <- data.frame()
results <- data.frame()
m[[i]] <- lm(all_formulas[i], data = d_train)
m[[i]] <- lm(all_formulas[[i]], data = d_train)
results$formula[i] <- all_formulas[[i]]
results <- data.frame()
results$formula[i] <- all_formulas[[i]]
crossval_res <- loocrossval(d_train, all_formulas[[i]])
loocrossval <- function(mydata, formula){
n <- nrow(mydata)  # Total number of observations
preds <- numeric(n)  # Placeholder for predictions
# Extract the outcome name from the formula
outcome_var <- all.vars(formula)[1]
# Leave-One-Out Cross-Validation
for (i in 1:n) {
# Define training and test sets
train_data <- mydata[-i, ]  # All except the i-th observation
test_data  <- mydata[i,  ]  # The i-th observation
# Fit the model
model <- lm(formula, data = train_data)
# Predict for the left-out observation
preds[i] <- predict(model, newdata = test_data)
}
# Compute Mean Squared Error
mse_loo <- mean((mydata[[outcome_var]] - preds)^2)
rsquared_loo <- 1 - (mse_loo/mean((mydata[[outcome_var]] - mean(mydata$y))^2))
res <- c(mse_loo, rsquared_loo)
names(res("MSE","r-squared"))
# result
return(res)
}
crossval_res <- loocrossval(d_train, all_formulas[[i]])
loocrossval <- function(mydata, formula){
n <- nrow(mydata)  # Total number of observations
preds <- numeric(n)  # Placeholder for predictions
# Extract the outcome name from the formula
outcome_var <- all.vars(formula)[1]
# Leave-One-Out Cross-Validation
for (i in 1:n) {
# Define training and test sets
train_data <- mydata[-i, ]  # All except the i-th observation
test_data  <- mydata[i,  ]  # The i-th observation
# Fit the model
model <- lm(formula, data = train_data)
# Predict for the left-out observation
preds[i] <- predict(model, newdata = test_data)
}
# Compute Mean Squared Error
mse_loo <- mean((mydata[[outcome_var]] - preds)^2)
rsquared_loo <- 1 - (mse_loo/mean((mydata[[outcome_var]] - mean(mydata$y))^2))
res <- c(mse_loo, rsquared_loo)
names(res) <- c("MSE","r-squared")
# result
return(res)
}
loocrossval <- function(mydata, formula){
n <- nrow(mydata)  # Total number of observations
preds <- numeric(n)  # Placeholder for predictions
# Extract the outcome name from the formula
outcome_var <- all.vars(formula)[1]
# Leave-One-Out Cross-Validation
for (i in 1:n) {
# Define training and test sets
train_data <- mydata[-i, ]  # All except the i-th observation
test_data  <- mydata[i,  ]  # The i-th observation
# Fit the model
model <- lm(formula, data = train_data)
# Predict for the left-out observation
preds[i] <- predict(model, newdata = test_data)
}
# Compute Mean Squared Error
mse_loo <- mean((mydata[[outcome_var]] - preds)^2)
rsquared_loo <- 1 - (mse_loo/mean((mydata[[outcome_var]] - mean(mydata$y))^2))
# return results as named vector
res <- c(mse_loo, rsquared_loo)
names(res) <- c("MSE","r-squared")
# result
return(res)
}
crossval_res <- loocrossval(d_train, all_formulas[[i]])
loocrossval <- function(mydata, formula){
n <- nrow(mydata)  # Total number of observations
preds <- numeric(n)  # Placeholder for predictions
# Extract the outcome name from the formula
outcome_var <- all.vars(formula)[1]
# Leave-One-Out Cross-Validation
for (i in 1:n) {
# Define training and test sets
train_data <- mydata[-i, ]  # All except the i-th observation
test_data  <- mydata[i,  ]  # The i-th observation
# Fit the model
model <- lm(formula, data = train_data)
# Predict for the left-out observation
preds[i] <- predict(model, newdata = test_data)
}
# Compute Mean Squared Error
mse_loo <- mean((mydata[[outcome_var]] - preds)^2)
rsquared_loo <- 1 - (mse_loo/mean((mydata[[outcome_var]] - mean(mydata[[outcome_var]]))^2))
# return results as named vector
res <- c(mse_loo, rsquared_loo)
names(res) <- c("MSE","r-squared")
# result
return(res)
}
crossval_res <- loocrossval(d_train, all_formulas[[i]])
formula = all_formulas[[i]]
outcome_var <- all.vars(formula)[1]
outcome_var
str(formula)
outcome_var <- all.vars(as.formula(formula))[1]
outcome_var
loocrossval <- function(mydata, formula){
n <- nrow(mydata)  # Total number of observations
preds <- numeric(n)  # Placeholder for predictions
# Extract the outcome name from the formula
outcome_var <- all.vars(as.formula(formula))[1]
# Leave-One-Out Cross-Validation
for (i in 1:n) {
# Define training and test sets
train_data <- mydata[-i, ]  # All except the i-th observation
test_data  <- mydata[i,  ]  # The i-th observation
# Fit the model
model <- lm(formula, data = train_data)
# Predict for the left-out observation
preds[i] <- predict(model, newdata = test_data)
}
# Compute Mean Squared Error
mse_loo <- mean((mydata[[outcome_var]] - preds)^2)
rsquared_loo <- 1 - (mse_loo/mean((mydata[[outcome_var]] - mean(mydata[[outcome_var]]))^2))
# return results as named vector
res <- c(mse_loo, rsquared_loo)
names(res) <- c("MSE","r-squared")
# result
return(res)
}
crossval_res <- loocrossval(d_train, all_formulas[[i]])
crossval_res
data.frame(crossval_res)
rbind(results, data.frame(MSE= crossval_res["MSE"],
r-squared = crossval_res["r-squared"],
crossval_res["r-squared"]
rbind(results, data.frame(MSE= crossval_res["MSE"],
r_squared = crossval_res["r-squared"],
formula = all_formulas[[i]]))
m <- list() # an empty list
results <- data.frame()
for (i in 1:length(all_formulas)) {
m[[i]] <- lm(all_formulas[[i]], data = d_train)
crossval_res <- loocrossval(d_train, all_formulas[[i]])
results <- rbind(results, data.frame(MSE= crossval_res["MSE"],
r_squared = crossval_res["r-squared"],
formula = all_formulas[[i]]))
}
crossval_res
print(crossval_res)
m <- list() # an empty list
results <- data.frame()
# warning: this step may take some time to complete!
for (i in 1:length(all_formulas)) {
m[[i]] <- lm(all_formulas[[i]], data = d_train)
crossval_res <- loocrossval(d_train, all_formulas[[i]])
cat("model ",i, "out of ", length(all_formulas), "completed:\n")
print(crossval_res)
cat("\n\n")
results <- rbind(results, data.frame(MSE= crossval_res["MSE"],
r_squared = crossval_res["r-squared"],
formula = all_formulas[[i]]))
}
str(results)
hist(results$MSE)
plot(results$MSE, results$r_squared)
results$formula[results$MSE==min(results$MSE)]
# LOO MSE error of best model
results$MSE[results$MSE==min(results$MSE)]
# LOO r-squared of best model
results$r_squared[results$MSE==min(results$MSE)]
best_model <- lm(best_formula, data = train_data)
best_formula <- results$formula[results$MSE==min(results$MSE)]
best_model <- lm(best_formula, data = train_data)
best_model <- lm(best_formula, data = d_train)
# Predict on test data
d_test <- read.csv("california_housing_test.csv")
preds <- predict(best_model, newdata = d_test)
mse <- mean((d_test$medv - preds)^2)
mse
best_model <- lm(medv ~ ., data = d_train)
preds <- predict(best_model, newdata = d_test)
# Calculate Mean Squared Error
mse <- mean((d_test$medv - preds)^2)
mse
best_model <- lm(best_formula, data = d_train)
# Predict on test data
d_test <- read.csv("california_housing_test.csv")
preds <- predict(best_model, newdata = d_test)
best_model <- lm(best_formula, data = d_train)
# Predict on test data
d_test <- read.csv("california_housing_test.csv")
preds <- predict(best_model, newdata = d_test)
best_formula <- results$formula[results$MSE==min(results$MSE)]
# LOO MSE error of best model
results$MSE[results$MSE==min(results$MSE)]
# LOO r-squared of best model
results$r_squared[results$MSE==min(results$MSE)]
# Calculate Mean Squared Error
mse <- mean((d_test$medv - preds)^2)
1 - (mse/mean((d_test$medv- mean(d_test$medv))^2))
# Calculate Mean Squared Error
mse <- mean((d_test$medv - preds)^2)
1 - (mse/mean((d_test$medv- mean(d_test$medv))^2))
hist(results$MSE)
hist(results$r-squared)
hist(results$r_squared)
hist(results$MSE)
saveRDS(results, "cali_results.RDS")
length(all_formulas)
length(all_formulas)
formulas[1:3]
all_formulas[1:3]
all_formulas[100]
all_formulas[100:105]
all_formulas[sample(length(all_formulas), 5)]
all_formulas[sample(length(all_formulas), 5)]
str(m)
results <- loadRDS("cali_results.RDS")
results <- readRDS("cali_results.RDS")
mean((d_test$medv- mean(d_test$medv))^2)
results$test_MSE <- NA
results$test_rsquared <- NA
MSE_tot_test <- mean((d_test$medv- mean(d_test$medv))^2)
for(i in 1:nrow(results)){
m_i <- lm(results$formula[i], data = d_train)
preds_i <- predict(m_i, newdata = d_test)
results$test_MSE[i] <- mean((d_test$medv - preds_i)^2)
results$test_rsquared[i] <- 1 - (results$test_MSE[i] / MSE_tot_test)
}
str(results)
with(results, (plotMSE, test_MSE))
with(results, plot(MSE, test_MSE))
abline(a=0, b=1)
with(results, plot(MSE, test_MSE), pch="*")
with(results, plot(MSE, test_MSE, pch="*"))
with(results, plot(MSE, test_MSE, pch="*", col="blue"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="red")
with(results, plot(MSE, test_MSE, pch=".", col="blue"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="red")
with(results, plot(MSE, test_MSE, pch=21, col="blue"))
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col="blue"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, cex=3, col="red")
abline(a=0, b=1)
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col="blue", xlim=c(10, 90), ylim=c(10, 90)))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, cex=3, col="red")
abline(a=0, b=1)
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col="blue", xlim=c(10, 90), ylim=c(10, 90)))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="red")
abline(a=0, b=1)
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col="blue",
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="red")
abline(a=0, b=1)
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col="dark grey",
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col=rgb(0,0,0,0.3),
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="red")
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="blue")
abline(a=0, b=1)
abline(a=0, b=1, lty=2)
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col=rgb(0,0,0,0.3),
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="blue")
abline(a=0, b=1, lty=2)
saveRDS(results, "cali_results.RDS")
results <- readRDS("cali_results.RDS")
str(results)
results <- results[,c("MSE","r_squared","formula")]
head(results)
knitr::opts_chunk$set(echo = TRUE)
best_formula <- results$formula[results$MSE==min(results$MSE)]
print(best_formula)
knitr::opts_chunk$set(echo = TRUE)
d_train <- read.csv("california_housing_train.csv")
str(d_train)
var_list <- colnames(d_train[,-which(colnames(d_train)=="medv")])
dependent_var <- "medv"
# empty list to hold all formulae
all_formulas <- list()
# generate combinations of variables
for(i in 1:length(var_list)){
combinations <- combn(var_list, i)
num_combinations <- ncol(combinations)
# loop over combinations and create formulas
for(j in 1:num_combinations){
formula <- paste(dependent_var, "~",
paste(combinations[,j], collapse="+"))
all_formulas <- c(all_formulas, formula)
}
}
length(all_formulas)
all_formulas[sample(length(all_formulas), 5)]
loocrossval <- function(mydata, formula){
n <- nrow(mydata)  # Total number of observations
preds <- numeric(n)  # Placeholder for predictions
# Extract the outcome name from the formula
outcome_var <- all.vars(as.formula(formula))[1]
# Leave-One-Out Cross-Validation
for (i in 1:n) {
# Define training and test sets
train_data <- mydata[-i, ]  # All except the i-th observation
test_data  <- mydata[i,  ]  # The i-th observation
# Fit the model
model <- lm(formula, data = train_data)
# Predict for the left-out observation
preds[i] <- predict(model, newdata = test_data)
}
# Compute Mean Squared Error
mse_loo <- mean((mydata[[outcome_var]] - preds)^2)
rsquared_loo <- 1 - (mse_loo/mean((mydata[[outcome_var]] - mean(mydata[[outcome_var]]))^2))
# return results as named vector
res <- c(mse_loo, rsquared_loo)
names(res) <- c("MSE","r-squared")
# result
return(res)
}
results <- readRDS("cali_results.RDS")
results <- results[,c("MSE","r_squared","formula")]
head(results)
best_formula <- results$formula[results$MSE==min(results$MSE)]
print(best_formula)
# LOO MSE error of best model
results$MSE[results$MSE==min(results$MSE)]
# LOO r-squared of best model
results$r_squared[results$MSE==min(results$MSE)]
# load test set
d_test <- read.csv("california_housing_test.csv")
# estimate the model parameters using training set data
best_model <- lm(best_formula, data = d_train)
# Predict values of test data
preds <- predict(best_model, newdata = d_test)
test_mse <- mean((d_test$medv - preds)^2)
test_rsquared <- 1 - (mse/mean((d_test$medv- mean(d_test$medv))^2))
1 - (mse/mean((d_test$medv- mean(d_test$medv))^2))
results <- readRDS("cali_results.RDS")
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col=rgb(0,0,0,0.3),
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="blue")
legent('topleft', col="blue", pch=19, label="selected by LOO-cross validation", bty="n")
legend('topleft', col="blue", pch=19, label="selected by LOO-cross validation", bty="n")
?legend
results <- readRDS("cali_results.RDS")
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col=rgb(0,0,0,0.3),
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="blue")
legend('topleft', col="blue", pch=19, legend="selected by LOO-cross validation", bty="n")
abline(a=0, b=1, lty=2)
results <- readRDS("cali_results.RDS")
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col=rgb(0,0,0,0.3),
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="blue")
legend('topleft', col="blue", pch=19, legend="selected by LOO-cross validation", bty="n")
abline(a=0, b=1, lty=2)
results <- readRDS("cali_results.RDS")
with(results, plot(MSE, test_MSE, pch=21, cex=0.2, col=rgb(0.4,0.4,0.4,0.5),
xlim=c(10, 90),
ylim=c(10, 90),
xlab="MSE train set (cross-validated)",
ylab="MSE test set"))
points(results$MSE[results$MSE==min(results$MSE)], mse, pch=19, col="blue")
legend('topleft', col="blue", pch=19, legend="selected by LOO-cross validation", bty="n")
abline(a=0, b=1, lty=2)
